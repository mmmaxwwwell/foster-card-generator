# Agent Documentation

This document provides context for AI agents working on the Foster Card Generator codebase.

## Purpose

Desktop application (Electron) for animal rescue organizations to create printable trading cards for foster animals. Cards print on Avery 8471 business card templates (10 per sheet) at 360 DPI.

## Architecture

```
Main Process (main.js)          Renderer Process (app/resources/js/app.js)
├── IPC handlers                ├── UI/DOM manipulation
├── Database access (sql.js)    ├── Form handling
├── Web scraping (Puppeteer)    └── Calls main via IPC
├── Card generation
└── Printing (platform-specific)
```

**Why Electron?** Cross-platform desktop app with shared JS codebase.

**Why sql.js?** Pure JavaScript SQLite - no native binding compilation issues in Electron.

**Why IPC separation?** Puppeteer requires main process; prevents renderer crashes.

## Key Directories

| Directory | Purpose |
|-----------|---------|
| `app/` | Main application code |
| `app/resources/` | UI (HTML, CSS, JS for renderer) |
| `app/db/` | Migrations and seeds |
| `src/` | Card templates (Handlebars), CSS, sample data |
| `db/` | Legacy schema (migrations now in `app/db/`) |

## Code Boundaries

### Database (`app/db.js`, `app/db/`)
All SQL execution, migrations, and BLOB handling. Never accessed directly from renderer - always via IPC.

### Scrapers (`app/scrape-*.js`)
Two independent implementations for different sites:
- **Wagtopia**: `scrape-url-wagtopia.js`, `scrape-list-wagtopia.js` - Puppeteer-based, JS-heavy pages
- **Adoptapet**: `scrape-url-adoptapet.js`, `scrape-list-adoptapet.js` - Cheerio-based, table HTML parsing

**Why two scrapers?** Sites have completely different DOM structures.

### Card Generation (`app/generate-card-cli.js`)
Renders HTML templates via Puppeteer at 360 DPI (deviceScaleFactor = 3.75). Returns PNG path.

### Printing (`app/print-windows.js`, `main.js`)
- **Windows**: PowerShell with .NET `System.Drawing.Printing` APIs for silent printing with calibration support
- **Linux/macOS**: Electron's `webContents.print()` API

**Why calibration?** Printers vary; ensures cards align with pre-cut Avery templates.

## Database Schema

Four tables: `rescues`, `animals`, `print_profiles`, `schema_migrations`

Logos and portraits stored as BLOBs - eliminates file path dependencies.

See [DATABASE.md](DATABASE.md) for full schema.

## Critical Files

| File | Lines | Role |
|------|-------|------|
| `main.js` | ~500 | Electron main process, all IPC handlers |
| `app/db.js` | ~800 | Database abstraction layer |
| `app/generate-card-cli.js` | ~400 | Card HTML to PNG rendering |
| `app/print-windows.js` | ~900 | Windows printing with calibration |
| `app/paths.js` | ~50 | Cross-platform path resolution |

## NixOS Integration

### Why Nix?
Reproducible builds with deterministic dependencies. Electron + Puppeteer + Sharp require many system libraries.

### Updating npm packages for NixOS

After modifying `package.json`:

```bash
# 1. Update package-lock.json
npm install

# 2. Regenerate node2nix files
node2nix -l package-lock.json -c node-packages.nix

# 3. Verify build
nix build
```

This regenerates `node-env.nix` and `node-packages.nix` with updated dependency hashes.

### Key Nix Files

| File | Purpose |
|------|---------|
| `flake.nix` | Main Nix configuration, packages, dev shell |
| `node-env.nix` | Generated by node2nix - build instructions |
| `node-packages.nix` | Generated by node2nix - dependency list (~300KB) |

### Environment Variables (NixOS)
- `PUPPETEER_EXECUTABLE_PATH`: Points to system Chromium
- `PUPPETEER_SKIP_DOWNLOAD`: Prevents Puppeteer downloading Chrome
- `LD_LIBRARY_PATH`: Electron runtime libraries

## Development Patterns

### IPC Communication
```javascript
// Main process
ipcMain.handle('action-name', async (event, data) => {
    try {
        return { success: true, data: result };
    } catch (error) {
        return { success: false, error: error.message };
    }
});

// Renderer process
const result = await ipcRenderer.invoke('action-name', data);
```

### Adding a New Scraper
1. Create `app/scrape-url-{sitename}.js` and `app/scrape-list-{sitename}.js`
2. Add IPC handlers in `main.js`
3. Add rescue entry with `scraper_type` in database seeds
4. Update UI to expose new scraper option

### Adding Database Migrations
1. Create `app/db/migrations/YYYYMMDDHHMMSS_description.js`
2. Export `up(db)` and `down(db)` functions
3. Migrations run automatically on startup

## Pre-Release Checklist

1. Update version in `package.json`
2. Update npm packages if needed: `npm update`
3. Regenerate node2nix files if package.json changed (see above)
4. Verify NixOS build: `nix build`
5. **Review this document for accuracy**
6. Run `npm run build` for Windows installer
7. Test on clean Windows install

## Conventions

- **Files**: kebab-case (`scrape-url-wagtopia.js`)
- **Functions**: camelCase
- **Database columns**: snake_case
- **No frameworks**: Vanilla DOM manipulation in renderer

## External Dependencies (Windows)

| Dependency | Required | Purpose |
|------------|----------|---------|
| PowerShell 5.0+ | Yes | Printing functionality (included in Windows 10/11) |
| .NET Framework | Yes | Printing APIs via PowerShell (included in Windows) |
| Chrome or Edge | Recommended | Web scraping via Puppeteer; falls back to bundled Chromium (~200MB download) if neither found |

### Browser Detection (`app/browser-helper.js`)
Puppeteer checks these paths in order:
1. `C:\Program Files\Google\Chrome\Application\chrome.exe`
2. `C:\Program Files (x86)\Google\Chrome\Application\chrome.exe`
3. `%LOCALAPPDATA%\Google\Chrome\Application\chrome.exe`
4. `C:\Program Files\Microsoft\Edge\Application\msedge.exe`
5. `C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe`
6. Falls back to bundled Chromium if none found

### What's NOT Required
- **SumatraPDF** - Not used; printing is handled via PowerShell
- **ImageMagick/GraphicsMagick** - Not used; image processing via Sharp npm package
- **External database** - Not used; sql.js is pure JavaScript SQLite
- **GIMP** - Only used on Linux/macOS for image editing

## Known Limitations

- TypeScript config exists but code is JavaScript
- Limited test coverage (only `test-scraper-integration.js`)
- Calibration values are magic numbers (could be more configurable)
